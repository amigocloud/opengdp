#!/bin/bash
# Copyright (c) 2011, Brian Case
#
# Permission is hereby granted, free of charge, to any person obtaining a
# copy of this software and associated documentation files (the "Software"),
# to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense,
# and/or sell copies of the Software, and to permit persons to whom the
# Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included
# in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
# DEALINGS IN THE SOFTWARE.


 
###############################################################################
# function to follow redirects on new earth explorer
#
###############################################################################

function NEE_redirect {
    local url="$1"
    local referer="$2"
    local tmpdir="$3"
    local headers="$4"
    local cookie="$5"
    local outfile="$6"
   
    ##### only recurse if there is a Location in the response headers #####
    
    if [[ -f "${tmpdir}/${headers}" ]] && \
       grep -q "${tmpdir}/${headers}" -e "^[lL]ocation:"
    then
        
        local location=$( grep "${tmpdir}/${headers}" -e "^[lL]ocation:" | \
                          sed 's/[lL]ocation: //' | \
                          sed 's:/[.]/:/:' | tr -d "\r")
        
        ##### does the location have a host? #####
        
        local host="$(url_get_host "$location")"
        if ! [ -n "$host" ]
        then
            location="$(url_get_proto "$url")://$(url_get_host "$url")${location}"
        fi
        
        find "$tmpdir" -name "${cookie}*" -exec mv {} {}.old \;
        find "$tmpdir" -name "${headers}*" -exec mv {} {}.old \;
        find "$tmpdir" -name "${outfile}*" -exec mv {} {}.old \;
        
        if [ -n "$referer" ]
        then
            
            curl "$location" \
                 "${curl_std_args[@]}" \
                 --referer "$referer" \
                 --cookie "${tmpdir}/${cookie}.old" \
                 --cookie-jar "${tmpdir}/${cookie}" \
                 --dump-header "${tmpdir}/${headers}" \
                 > "${tmpdir}/${outfile}" \
                 2> /dev/null || return 1
        else
                 
            curl "$location" \
                 "${curl_std_args[@]}" \
                 --cookie "${tmpdir}/${cookie}.old" \
                 --cookie-jar "${tmpdir}/${cookie}" \
                 --dump-header "${tmpdir}/${headers}" \
                 > "${tmpdir}/${outfile}" \
                 2> /dev/null || return 1
        fi
        
        ##### check if the output is gzipped #####
        
        if [ -f "${tmpdir}/${outfile}" ] && \
           grep -q "${tmpdir}/${headers}" -e "Content-Encoding: gzip"
        then
            mv "${tmpdir}/${outfile}" "${tmpdir}/${outfile}.gz"
            zcat "${tmpdir}/${outfile}.gz" > "${tmpdir}/${outfile}"
        fi
        
        local lastlocation
        lastlocation=$( NEE_redirect "$location" "$referer" "$tmpdir" \
                                      "$headers" "$cookie" "$outfile") || return 1
        
        echo "$lastlocation"
    
    ##### no location? return the url #####
    
    else
        echo "$url"
    fi
    
}

###############################################################################
# function to log into new earth explorer
#
# vars NewEarthExplorer_user NewEarthExplorer_pass must be set
#
###############################################################################

function NEE_login {
    local url="$1"
    local referer="$2"
    local tmpdir="$3"
    local oldcookie="$4"
    local cookie="$5"
    local headers="$6"
    local outfile="$7"
    
    curl "$url" \
         "${curl_std_args[@]}" \
         --referer "${referer}" \
         --cookie "${tmpdir}/${oldcookie}" \
         --cookie-jar "${tmpdir}/${cookie}" \
         --dump-header "${tmpdir}/${headers}" \
         --data-urlencode "username=$NewEarthExplorer_user" \
         --data-urlencode "password=$NewEarthExplorer_pass" \
         --data-urlencode "rememberMe=0" \
         --data-urlencode "submit=" \
         > "${tmpdir}/${outfile}" \
         2> /dev/null #|| { printerror "login" ; return 1 }
    
    ##### check if the output is gzipped #####
        
    if [ -f "${tmpdir}/${outfile}" ] && \
       grep -q "${tmpdir}/${headers}" -e "Content-Encoding: gzip"
    then
        mv "${tmpdir}/${outfile}" "${tmpdir}/${outfile}.gz"
        zcat "${tmpdir}/${outfile}.gz" > "${tmpdir}/${outfile}"
    fi
    
    NEE_redirect "$url" "$referer" "$tmpdir" \
                 "$headers" "$cookie" "${outfile}" || return 1
        
    
}

###############################################################################
# function std curl call with a recursive redirect
###############################################################################

function NEE_curl {
    local url="$1"
    local referer="$2"
    local tmpdir="$3"
    local oldcookie="$4"
    local cookie="$5"
    local headers="$6"
    local outfile="$7"
    
    if [ -n "$referer" ]
    then
        
        curl "$url" \
             "${curl_std_args[@]}" \
             --referer "$referer" \
             --cookie "${tmpdir}/${oldcookie}" \
             --cookie-jar "${tmpdir}/${cookie}" \
             --dump-header "${tmpdir}/${headers}" \
             > "${tmpdir}/${outfile}" \
             2> /dev/null #|| { printerror "getdownload" ; return 1 }
    else
             
        curl "$url" \
             "${curl_std_args[@]}" \
             --cookie "${tmpdir}/${oldcookie}" \
             --cookie-jar "${tmpdir}/${cookie}" \
             --dump-header "${tmpdir}/${headers}" \
             > "${tmpdir}/${outfile}" \
             2> /dev/null #|| { printerror "getdownload" ; return 1 }
    fi
        
    ##### check if the output is gzipped #####
        
    if [ -f "${tmpdir}/${outfile}" ] && \
       grep -q "${tmpdir}/${headers}" -e "Content-Encoding: gzip"
    then
        mv "${tmpdir}/${outfile}" "${tmpdir}/${outfile}.gz"
        zcat "${tmpdir}/${outfile}.gz" > "${tmpdir}/${outfile}"
    fi
    
    NEE_redirect "$url" "$referer" "$tmpdir" \
                 "$headers" "$cookie" "${outfile}" || return 1

}


###############################################################################
# main function to get a file from new earth explorer
#
# vars NewEarthExplorer_user NewEarthExplorer_pass must be set
#
# usage: NewEarthExplorer_get "<url> <outdir>
# http://edcsns17.cr.usgs.gov/NewEarthExplorer/order/process?node=RS&dataset_name=LANDSAT_ETM_SLC_OFF&ordered=LE71270312011259EDC00
###############################################################################

function NewEarthExplorer_get {
    local url="$1"
    local oldtmpdir="$2"
    
    local urlenc="$(url_encode "$url")"
    
    local proto="$(url_get_proto $url)"
    local host="$(url_get_host $url)"
    local path="$(url_get_path $url)"
    local query="$(url_get_query $url)"
    
    local loginurl="https://${host}/NewEarthExplorer/login"
    local logouturl="${proto}://${host}/NewEarthExplorer/logout/"
    local referer="${proto}://${host}${path%/*}/"
    #--header "Host: $host"
       
    curl_std_args=(
        --user-agent "User-Agent: Mozilla/5.0 (X11; U; Linux x86_64; en-US; rv:1.9.2.15) Gecko/20110324 Gentoo Firefox/3.6.15"
        --header "Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
        --header "Accept-Language: en-us,en;q=0.5"
        --header "Accept-Encoding: gzip,deflate"
        --header "Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7"
        --header "Keep-Alive: 115"
        --header "Connection: keep-alive" )

    local tmpdir
    tmpdir=$(mktemp -d -p "${oldtmpdir}" "${dsname}XXXXXXXXXX") #|| { printerror "create tmpdir" ; return 1 }
    

    ##### get the login page #####
    
    local lasturl
    
    touch "${tmpdir}/prelogin.cookie"
    
    lasturl=$( NEE_curl "${url}" "" "$tmpdir" "prelogin.cookie" \
                         "getlogin.cookie" "getlogin.header" \
                         "getlogin.out" ) || {
        rm -r "${tmpdir}"
        return 1
    }
    
    ##### login #####
    
    lasturl=$( NEE_login "$lasturl" "$lasturl" "$tmpdir" "getlogin.cookie" \
                         "login.cookie" "login.header" \
                         "login.out") || {
        rm -r "${tmpdir}"
        return 1
    }
    
    if ! [ -f "${tmpdir}/login.out" ] || \
       ! grep -q "${tmpdir}/login.out" -e "dlInfo"
    then
        NEE_curl "$logouturl" "${lasturl}" "$tmpdir" "login.cookie" \
                 "logout.cookie" "logout.header" "logout.out" > /dev/null
        rm -r "$tmpdir"
        return 1
    
    fi
    
    lasturl="http://edcsns17.cr.usgs.gov/NewEarthExplorer/order"
    ##### get the dlinfo #####
    
    local junk atom collection
    IFS='|'
    read junk junk atom junk collection < <( grep  */login.out -e dlInfo |\
                                              sed 's/.*id=\"\(.*\)">.*/\1/' )
    unset IFS
    
    local pupurl="${proto}://${host}/NewEarthExplorer/ajax/getdownloadoptions?collection_id=${collection}&entity_id=${atom}"
    
    ##### get popup download window #####
    
    lasturl=$( NEE_curl "$pupurl" "${lasturl}" "$tmpdir" "login.cookie" \
                        "getpopup.cookie" "getpopup.header" \
                        "getpopup.out" )  || {
        NEE_curl "$logouturl" "${lasturl}" "$tmpdir" "login.cookie" \
                 "logout.cookie" "logout.header" "logout.out" > /dev/null
        rm -r "$tmpdir"
        return 1
    }
    
    ##### does the download window have a standard download? #####

    if cat "${tmpdir}/getpopup.out" | sed 's/,/\n/g' | grep -q STANDARD
    then
        local next=$(cat "${tmpdir}/getpopup.out" |\
                      sed 's/,/\n/g' |\
                      grep STANDARD |\
                      sed -e 's/"//g' \
                          -e 's/url://' \
                          -e 's/\\//g')

        ##### goto next download window to get the real url #####
        
        lasturl=$( NEE_curl "${proto}://${host}${next}&operation=get" "${lasturl}" "$tmpdir" \
                          "getpopup.cookie" "getdownload.cookie" \
                          "getdownload.header" \
                          "getdownload.out" ) || {
            NEE_curl "$logouturl" "${lasturl}" "$tmpdir" "getpopup.header" \
                     "logout.cookie" "logout.header" "logout.out" > /dev/null
            rm -r "$tmpdir"
            return 1
        }
            
        ##### get the download url #####
        
        if ! [ -f "${tmpdir}/getdownload.out" ] || \
           ! grep -q "${tmpdir}/getdownload.out" -e downloadURL
        then
            NEE_curl "$logouturl" "${lasturl}" "$tmpdir" "getdownload.cookie" \
                     "logout.cookie" "logout.header" "logout.out"  > /dev/null
            rm -r "$tmpdir"
            return 1
        fi
        
        down=$(grep "${tmpdir}/getdownload.out" -e downloadURL |\
                sed 's;.*href="\(.*\)".*;\1;')
        
        ###### download the file #####

        NEE_curl "$down" "${lasturl}" "$tmpdir" \
                 "getdownload.cookie" "download.cookie" \
                 "download.header" \
                 "download.out" > /dev/null || return 1

        ##### rename the file ##### 

        if grep -q "${tmpdir}/download.header" -e "filename="
        then
            outfile=$(grep "${tmpdir}/download.header" -e filename= |\
                      sed 's/.*filename=//' |\
                      tr -d "\r" )
            mv "${tmpdir}/download.out" "$outfile"
            
            echo "$outfile"
        fi

        ##### logout #####
    
        NEE_curl "$logouturl" "${lasturl}" "$tmpdir" "download.cookie" \
                 "logout.cookie" "logout.header" \
                 "logout.out" > /dev/null || return 1
    
    else
    
        ##### need to add an option to order items that do not already have a standard download #####

        ##### logout #####
    
        NEE_curl "$logouturl" "${lasturl}" "$tmpdir" "getpopup.cookie" \
                 "logout.cookie" "logout.header" \
                 "logout.out" > /dev/null || return 1
       
    fi
    
    ##### cleanup temp dir #####
    
    rm -r "$tmpdir"
    
}

